# Articles, Journals, Blogs, Research, Workbooks, Guidelines, White Papers

A collection of thought pieces and published artifacts organized by governance category. This corpus influenced the work of this repository and serves as a Library of resources for anyone wishing to go deeper on the topic or do their own research across the evolving technology space.

If you would like to suggest a resource, create an issue (or reach out directly) & it will be reviewed for inclusion.

**Resources are not listed under category in any order of importance, only the order in which they were added.*

## Regulatory Compliance 
(Federated, Capability Driven, Context-Aware, Reusable Components, Adaptive)
- [Overcoming two issues that are sinking gen AI programs](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/overcoming-two-issues-that-are-sinking-gen-ai-programs) - by Jacobsen/Witte/Kazmier/Villarreal via Mckinsey & Company (blog)

## Observability
(Continuous, Real-Time, Automated, Outcome Driven, Evaluation Loops, Token-Level)

## Transparency
(Traceable, Lineaged, Coherent, Useful)


## Explainability
(Documented, Cited, Hallucination-Managed, Immutable, Role-Based)
- [If a Model Decision Can Impact a Customer's Life, It Must Be Explainable](https://medium.com/@slsarath2/if-a-model-decision-can-impact-a-customers-life-it-must-be-explainable-2534f7199b47) - by Sarath SL (medium)
- [Humanity's Last Exam](https://agi.safe.ai/) - (research)
- [Scholars: AI isn't 'hallucinating' -it's bullshitting](https://www.psypost.org/scholars-ai-isnt-hallucinating-its-bullshitting/) - Dolan, PsyPost

## Security
(Privacy, Policy-as-Code, Embedded, Risk Toleranced, Protected)
- [Privacy and Data Protection Risks in Large Language Models (LLMs)](https://rm.coe.int/privacy-and-data-protection-risks-in-large-language-models-llms-v1-0/1680b631dd) - by Barbera & Popa-Fabre (white paper)
- [On Protecting the Data Privacy of Large Language Models (LLMs): A Survey](https://arxiv.org/pdf/2403.05156) - by Yan/Li/Xu/Dong/Zhang/Ren/Cheng (white paper)
- [MIT AI Risk Repository](https://airisk.mit.edu/) - (website)
- [A New Kind of AI Model Let's Data Owners Take Control](https://www.wired.com/story/flexolmo-ai-model-lets-data-owners-take-control/) - by Will Knight (Wired)
- [FlexOlmo: Open Language Models for Flexible Data Use](https://www.datocms-assets.com/64837/1752084947-flexolmo-5.pdf) - by Shi/Bhagia/Farhat/Muennighoff/Walsh/Morrison (white paper)
  
## Responsible AI
(Ethical, Fair, Unbiased)
- [Responsible AI Progress Report](https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf) - Google, Feb 2025
- [The Impossibility of Fair LLMs](https://aclanthology.org/2025.acl-long.5/) - by Anthis/Lum/Ekstrand/Feller/Tan (research)
- [Responsible AI (RAI) Principles](https://www.mckinsey.com/capabilities/quantumblack/how-we-help-clients/generative-ai/responsible-ai-principles) - Mckinsey & Company

## Sustainability
(Environmental, Performant, Budgeted)
- [The Era of 1-bit LLMS: All Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764) - by Ma/Wang/Ma/Wang/Wang/Huang/Dong/Wang/Xue/Wei (white paper)
- [ITU: Measuring What Matters: How to Assess AI's Environmental Impact](https://www.itu.int/hub/publication/s-gen-gda-001-2025/) - (research)
- [New AI Architecture delivers 100x faster reasoning than LLMs with just 1k Training Examples](https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/) - by Ben Dickson (VentureBeat)

## General Guidelines & Frameworks
- [IAPS - AI Agent Governance: A Field Guide](https://static1.squarespace.com/static/64edf8e7f2b10d716b5ba0e1/t/6801438c58c2692374995db0/1744913293841/Agent+Governance_+A+Field+Guide.pdf) - April 2025
- [Databricks AI Governance Framework 1.0](https://www.databricks.com/sites/default/files/2025-06/databricks-183717-whitepaper-databricks-ai-governance-framework.pdf) - July 2025
